{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Kaynak: https://blog.varunajayasiri.com/numpy_lstm.html\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T13:25:40.425259Z",
     "start_time": "2020-04-02T13:25:40.379381Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T13:25:41.533128Z",
     "start_time": "2020-04-02T13:25:41.522158Z"
    }
   },
   "outputs": [],
   "source": [
    "data = open('input.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data and calculate indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T13:25:42.324385Z",
     "start_time": "2020-04-02T13:25:42.312389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 99992 characters, 62 unique\n"
     ]
    }
   ],
   "source": [
    "chars = list(set(data))\n",
    "data_size, X_size = len(data), len(chars)\n",
    "print(\"data has %d characters, %d unique\" % (data_size, X_size))\n",
    "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
    "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T13:25:43.160940Z",
     "start_time": "2020-04-02T13:25:43.154959Z"
    }
   },
   "outputs": [],
   "source": [
    "H_size = 100 # Size of the hidden layer\n",
    "T_steps = 25 # Number of time steps (length of the sequence) used for training\n",
    "learning_rate = 1e-1 # Learning rate\n",
    "weight_sd = 0.1 # Standard deviation of weights for initialization\n",
    "z_size = H_size + X_size # Size of concatenate(H, X) vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions and Derivatives\n",
    "\n",
    "#### Sigmoid\n",
    "\n",
    "\\begin{align}\n",
    "\\sigma(x) &= \\frac{1}{1 + e^{-x}}\\\\\n",
    "\\frac{d\\sigma(x)}{dx} &= \\sigma(x) \\cdot (1 - \\sigma(x))\n",
    "\\end{align}\n",
    "\n",
    "#### Tanh\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{d\\text{tanh}(x)}{dx} &= 1 - \\text{tanh}^2(x)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T13:25:44.378978Z",
     "start_time": "2020-04-02T13:25:44.368011Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def dtanh(y):\n",
    "    return 1 - y * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T13:27:03.637864Z",
     "start_time": "2020-04-02T13:27:03.631908Z"
    }
   },
   "outputs": [],
   "source": [
    "class Param:\n",
    "    def __init__(self, name, value):\n",
    "        self.name = name # Weight matrisinin ismi\n",
    "        self.v = value #parameter value #Random Gelecek Weight Değeri\n",
    "        self.d = np.zeros_like(value) #derivative #Türev Değeri\n",
    "        self.m = np.zeros_like(value) #momentum for AdaGrad #Momentum Değeri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use random weights with normal distribution (`0`, `weight_sd`) for $tanh$ activation function and (`0.5`, `weight_sd`) for $sigmoid$ activation function.\n",
    "\n",
    "Biases are initialized to zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:13:04.394021Z",
     "start_time": "2020-04-02T02:13:04.375042Z"
    }
   },
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.W_f = Param('W_f', \n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_f = Param('b_f',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_i = Param('W_i',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_i = Param('b_i',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_C = Param('W_C',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd)\n",
    "        self.b_C = Param('b_C',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_o = Param('W_o',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_o = Param('b_o',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        #For final layer to predict the next character\n",
    "        self.W_v = Param('W_v',\n",
    "                         np.random.randn(X_size, H_size) * weight_sd)\n",
    "        self.b_v = Param('b_v',\n",
    "                         np.zeros((X_size, 1)))\n",
    "        \n",
    "    def all(self):\n",
    "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
    "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
    "        \n",
    "parameters = Parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass\n",
    "\n",
    "![LSTM](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
    "\n",
    "*Operation $z$ is the concatenation of $x$ and $h_{t-1}$*\n",
    "\n",
    "#### Concatenation of $h_{t-1}$ and $x_t$\n",
    "\\begin{align}\n",
    "z & = [h_{t-1}, x_t] \\\\\n",
    "\\end{align}\n",
    "\n",
    "#### LSTM functions\n",
    "\\begin{align}\n",
    "f_t & = \\sigma(W_f \\cdot z + b_f) \\\\\n",
    "i_t & = \\sigma(W_i \\cdot z + b_i) \\\\\n",
    "\\bar{C}_t & = tanh(W_C \\cdot z + b_C) \\\\\n",
    "C_t & = f_t * C_{t-1} + i_t * \\bar{C}_t \\\\\n",
    "o_t & = \\sigma(W_o \\cdot z + b_t) \\\\\n",
    "h_t &= o_t * tanh(C_t) \\\\\n",
    "\\end{align}\n",
    "\n",
    "#### Logits\n",
    "\\begin{align}\n",
    "v_t &= W_v \\cdot h_t + b_v \\\\\n",
    "\\end{align}\n",
    "\n",
    "#### Softmax\n",
    "\\begin{align}\n",
    "\\hat{y_t} &= \\text{softmax}(v_t)\n",
    "\\end{align}\n",
    "\n",
    "$\\hat{y_t}$ is `y` in code and $y_t$ is `targets`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:13:06.771794Z",
     "start_time": "2020-04-02T02:13:06.763809Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward(x, h_prev, C_prev, p = parameters):\n",
    "    assert x.shape == (X_size, 1)\n",
    "    assert h_prev.shape == (H_size, 1)\n",
    "    assert C_prev.shape == (H_size, 1)\n",
    "    \n",
    "    z = np.row_stack((h_prev, x))\n",
    "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
    "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
    "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
    "\n",
    "    C = f * C_prev + i * C_bar\n",
    "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
    "    h = o * tanh(C)\n",
    "\n",
    "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
    "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
    "\n",
    "    return z, f, i, C_bar, C, o, h, v, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass\n",
    "\n",
    "#### Loss\n",
    "\n",
    "\\begin{align}\n",
    "L_k &= -\\sum_{t=k}^T\\sum_j y_{t,j} log \\hat{y_{t,j}} \\\\\n",
    "L &= L_1 \\\\\n",
    "\\end{align}\n",
    "\n",
    "#### Gradients\n",
    "\n",
    "\\begin{align}\n",
    "dv_t &= \\hat{y_t} - y_t \\\\\n",
    "dh_t &= dh'_t + W_y^T \\cdot dv_t \\\\\n",
    "do_t &= dh_t * \\text{tanh}(C_t) \\\\\n",
    "dC_t &= dC'_t + dh_t * o_t * (1 - \\text{tanh}^2(C_t))\\\\\n",
    "d\\bar{C}_t &= dC_t * i_t \\\\\n",
    "di_t &= dC_t * \\bar{C}_t \\\\\n",
    "df_t &= dC_t * C_{t-1} \\\\\n",
    "\\\\\n",
    "df'_t &= f_t * (1 - f_t) * df_t \\\\\n",
    "di'_t &= i_t * (1 - i_t) * di_t \\\\\n",
    "d\\bar{C}'_{t-1} &= (1 - \\bar{C}_t^2) * d\\bar{C}_t \\\\\n",
    "do'_t &= o_t * (1 - o_t) * do_t \\\\\n",
    "dz_t &= W_f^T \\cdot df'_t \\\\\n",
    "     &+ W_i^T \\cdot di_t \\\\\n",
    "     &+ W_C^T \\cdot d\\bar{C}_t \\\\\n",
    "     &+ W_o^T \\cdot do_t \\\\\n",
    "\\\\\n",
    "[dh'_{t-1}, dx_t] &= dz_t \\\\\n",
    "dC'_t &= f_t * dC_t\n",
    "\\end{align}\n",
    "\n",
    "* $dC'_t = \\frac{\\partial L_{t+1}}{\\partial C_t}$ and $dh'_t = \\frac{\\partial L_{t+1}}{\\partial h_t}$\n",
    "* $dC_t = \\frac{\\partial L}{\\partial C_t} = \\frac{\\partial L_t}{\\partial C_t}$ and $dh_t = \\frac{\\partial L}{\\partial h_t} = \\frac{\\partial L_{t}}{\\partial h_t}$\n",
    "* All other derivatives are of $L$\n",
    "* `target` is target character index $y_t$\n",
    "* `dh_next` is $dh'_{t}$ (size H x 1)\n",
    "* `dC_next` is $dC'_{t}$ (size H x 1)\n",
    "* `C_prev` is $C_{t-1}$ (size H x 1)\n",
    "* $df'_t$, $di'_t$, $d\\bar{C}'_t$, and $do'_t$ are *also* assigned to `df`, `di`, `dC_bar`, and `do` in the **code**.\n",
    "* *Returns* $dh_t$ and $dC_t$\n",
    "\n",
    "#### Model parameter gradients\n",
    "\n",
    "\\begin{align}\n",
    "dW_v &= dv_t \\cdot h_t^T \\\\\n",
    "db_v &= dv_t \\\\\n",
    "\\\\\n",
    "dW_f &= df'_t \\cdot z^T \\\\\n",
    "db_f &= df'_t \\\\\n",
    "\\\\\n",
    "dW_i &= di'_t \\cdot z^T \\\\\n",
    "db_i &= di'_t \\\\\n",
    "\\\\\n",
    "dW_C &= d\\bar{C}'_t \\cdot z^T \\\\\n",
    "db_C &= d\\bar{C}'_t \\\\\n",
    "\\\\\n",
    "dW_o &= do'_t \\cdot z^T \\\\\n",
    "db_o &= do'_t \\\\\n",
    "\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:13:08.956567Z",
     "start_time": "2020-04-02T02:13:08.941607Z"
    }
   },
   "outputs": [],
   "source": [
    "def backward(target, dh_next, dC_next, C_prev,\n",
    "             z, f, i, C_bar, C, o, h, v, y,\n",
    "             p = parameters):\n",
    "    \n",
    "    assert z.shape == (X_size + H_size, 1)\n",
    "    assert v.shape == (X_size, 1)\n",
    "    assert y.shape == (X_size, 1)\n",
    "    \n",
    "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
    "        assert param.shape == (H_size, 1)\n",
    "        \n",
    "    dv = np.copy(y)\n",
    "    dv[target] -= 1\n",
    "\n",
    "    p.W_v.d += np.dot(dv, h.T)\n",
    "    p.b_v.d += dv\n",
    "\n",
    "    dh = np.dot(p.W_v.v.T, dv)        \n",
    "    dh += dh_next\n",
    "    do = dh * tanh(C)\n",
    "    do = dsigmoid(o) * do\n",
    "    p.W_o.d += np.dot(do, z.T)\n",
    "    p.b_o.d += do\n",
    "\n",
    "    dC = np.copy(dC_next)\n",
    "    dC += dh * o * dtanh(tanh(C))\n",
    "    dC_bar = dC * i\n",
    "    dC_bar = dtanh(C_bar) * dC_bar\n",
    "    p.W_C.d += np.dot(dC_bar, z.T)\n",
    "    p.b_C.d += dC_bar\n",
    "\n",
    "    di = dC * C_bar\n",
    "    di = dsigmoid(i) * di\n",
    "    p.W_i.d += np.dot(di, z.T)\n",
    "    p.b_i.d += di\n",
    "\n",
    "    df = dC * C_prev\n",
    "    df = dsigmoid(f) * df\n",
    "    p.W_f.d += np.dot(df, z.T)\n",
    "    p.b_f.d += df\n",
    "\n",
    "    dz = (np.dot(p.W_f.v.T, df)\n",
    "         + np.dot(p.W_i.v.T, di)\n",
    "         + np.dot(p.W_C.v.T, dC_bar)\n",
    "         + np.dot(p.W_o.v.T, do))\n",
    "    dh_prev = dz[:H_size, :]\n",
    "    dC_prev = f * dC\n",
    "    \n",
    "    return dh_prev, dC_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear gradients before each backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:13:10.874879Z",
     "start_time": "2020-04-02T02:13:10.869891Z"
    }
   },
   "outputs": [],
   "source": [
    "def clear_gradients(params = parameters):\n",
    "    for p in params.all():\n",
    "        p.d.fill(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip gradients to mitigate exploding gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:13:12.182202Z",
     "start_time": "2020-04-02T02:13:12.178184Z"
    }
   },
   "outputs": [],
   "source": [
    "def clip_gradients(params = parameters):\n",
    "    for p in params.all():\n",
    "        np.clip(p.d, -1, 1, out=p.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
    "\n",
    "* `input`, `target` are list of integers, with character indexes.\n",
    "* `h_prev` is the array of initial `h` at $h_{-1}$ (size H x 1)\n",
    "* `C_prev` is the array of initial `C` at $C_{-1}$ (size H x 1)\n",
    "* *Returns* loss, final $h_T$ and $C_T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:13:13.461556Z",
     "start_time": "2020-04-02T02:13:13.447569Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_backward(inputs, targets, h_prev, C_prev):\n",
    "    global paramters\n",
    "    \n",
    "    # To store the values for each time step\n",
    "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
    "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
    "    v_s, y_s =  {}, {}\n",
    "    \n",
    "    # Values at t - 1\n",
    "    h_s[-1] = np.copy(h_prev)\n",
    "    C_s[-1] = np.copy(C_prev)\n",
    "    \n",
    "    loss = 0\n",
    "    # Loop through time steps\n",
    "    assert len(inputs) == T_steps\n",
    "    for t in range(len(inputs)):\n",
    "        x_s[t] = np.zeros((X_size, 1))\n",
    "        x_s[t][inputs[t]] = 1 # Input character\n",
    "        \n",
    "        (z_s[t], f_s[t], i_s[t],\n",
    "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
    "        v_s[t], y_s[t]) = \\\n",
    "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
    "            \n",
    "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
    "        \n",
    "    clear_gradients()\n",
    "\n",
    "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
    "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
    "\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        # Backward pass\n",
    "        dh_next, dC_next = \\\n",
    "            backward(target = targets[t], dh_next = dh_next,\n",
    "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
    "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
    "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
    "                     y = y_s[t])\n",
    "\n",
    "    clip_gradients()\n",
    "        \n",
    "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample the next character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:13:14.463244Z",
     "start_time": "2020-04-02T02:13:14.458255Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
    "    x = np.zeros((X_size, 1))\n",
    "    x[first_char_idx] = 1\n",
    "\n",
    "    h = h_prev\n",
    "    C = C_prev\n",
    "\n",
    "    indexes = []\n",
    "    \n",
    "    for t in range(sentence_length):\n",
    "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
    "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
    "        x = np.zeros((X_size, 1))\n",
    "        x[idx] = 1\n",
    "        indexes.append(idx)\n",
    "\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (Adagrad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the graph and display a sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:13:16.332614Z",
     "start_time": "2020-04-02T02:13:16.326628Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_status(inputs, h_prev, C_prev):\n",
    "    #initialized later\n",
    "    global plot_iter, plot_loss\n",
    "    global smooth_loss\n",
    "    \n",
    "    # Get predictions for 200 letters with current model\n",
    "\n",
    "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
    "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
    "\n",
    "    # Clear and plot\n",
    "    plt.plot(plot_iter, plot_loss)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()\n",
    "\n",
    "    #Print prediction and loss\n",
    "    print(\"----\\n %s \\n----\" % (txt, ))\n",
    "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update parameters\n",
    "\n",
    "\\begin{align}\n",
    "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
    "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:13:18.174211Z",
     "start_time": "2020-04-02T02:13:18.169224Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_paramters(params = parameters):\n",
    "    for p in params.all():\n",
    "        p.m += p.d * p.d # Calculate sum of gradients\n",
    "        #print(learning_rate * dparam)\n",
    "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delay the keyboard interrupt to prevent the training \n",
    "from stopping in the middle of an iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:13:19.171324Z",
     "start_time": "2020-04-02T02:13:19.164341Z"
    }
   },
   "outputs": [],
   "source": [
    "import signal\n",
    "\n",
    "class DelayedKeyboardInterrupt(object):\n",
    "    def __enter__(self):\n",
    "        self.signal_received = False\n",
    "        self.old_handler = signal.signal(signal.SIGINT, self.handler)\n",
    "\n",
    "    def handler(self, sig, frame):\n",
    "        self.signal_received = (sig, frame)\n",
    "        print('SIGINT received. Delaying KeyboardInterrupt.')\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.signal(signal.SIGINT, self.old_handler)\n",
    "        if self.signal_received:\n",
    "            self.old_handler(*self.signal_received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:13:20.441048Z",
     "start_time": "2020-04-02T02:13:20.435036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exponential average of loss\n",
    "# Initialize to a error of a random model\n",
    "smooth_loss = -np.log(1.0 / X_size) * T_steps\n",
    "\n",
    "iteration, pointer = 0, 0\n",
    "\n",
    "# For the graph\n",
    "plot_iter = np.zeros((0))\n",
    "plot_loss = np.zeros((0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:14:16.218690Z",
     "start_time": "2020-04-02T02:13:21.425501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " ll a, eshathad r oun ae we, th\n",
      ":\n",
      ",\n",
      "\n",
      "og og lindrusbedil lhalleseeehlU thecef boy piOhd d lesirrd brCI e shwisimhehelivoopvi \n",
      "I ul : ase\n",
      "uns.\n",
      "agd shd oyelasrgard\n",
      "arecer,\n",
      " aw thlt an I: soph ur'ton, urr\n",
      " \n",
      "----\n",
      "iter 1701, loss 81.567607\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        with DelayedKeyboardInterrupt():\n",
    "            # Reset\n",
    "            if pointer + T_steps >= len(data) or iteration == 0:\n",
    "                g_h_prev = np.zeros((H_size, 1))\n",
    "                g_C_prev = np.zeros((H_size, 1))\n",
    "                pointer = 0\n",
    "\n",
    "\n",
    "            inputs = ([char_to_idx[ch] \n",
    "                       for ch in data[pointer: pointer + T_steps]])\n",
    "            targets = ([char_to_idx[ch] \n",
    "                        for ch in data[pointer + 1: pointer + T_steps + 1]])\n",
    "\n",
    "            loss, g_h_prev, g_C_prev = \\\n",
    "                forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "            smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "            # Print every hundred steps\n",
    "            if iteration % 100 == 0:\n",
    "                update_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "            update_paramters()\n",
    "\n",
    "            plot_iter = np.append(plot_iter, [iteration])\n",
    "            plot_loss = np.append(plot_loss, [loss])\n",
    "\n",
    "            pointer += T_steps\n",
    "            iteration += 1\n",
    "    except KeyboardInterrupt:\n",
    "        update_status(inputs, g_h_prev, g_C_prev)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Gradient Check\n",
    "\n",
    "Approximate the numerical gradients by changing parameters and running the model. Check if the approximated gradients are equal to the computed analytical gradients (by backpropagation).\n",
    "\n",
    "Try this on `num_checks` individual paramters picked randomly for each weight matrix and bias vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:14:25.692111Z",
     "start_time": "2020-04-02T02:14:25.689146Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from random import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculate numerical gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:14:26.917117Z",
     "start_time": "2020-04-02T02:14:26.910165Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calc_numerical_gradient(param, idx, delta, inputs, target, h_prev, C_prev):\n",
    "    old_val = param.v.flat[idx]\n",
    "    \n",
    "    # evaluate loss at [x + delta] and [x - delta]\n",
    "    param.v.flat[idx] = old_val + delta\n",
    "    loss_plus_delta, _, _ = forward_backward(inputs, targets,\n",
    "                                             h_prev, C_prev)\n",
    "    param.v.flat[idx] = old_val - delta\n",
    "    loss_mins_delta, _, _ = forward_backward(inputs, targets, \n",
    "                                             h_prev, C_prev)\n",
    "    \n",
    "    param.v.flat[idx] = old_val #reset\n",
    "\n",
    "    grad_numerical = (loss_plus_delta - loss_mins_delta) / (2 * delta)\n",
    "    # Clip numerical error because analytical gradient is clipped\n",
    "    [grad_numerical] = np.clip([grad_numerical], -1, 1) \n",
    "    \n",
    "    return grad_numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Check gradient of each paramter matrix/vector at `num_checks` individual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:14:28.134479Z",
     "start_time": "2020-04-02T02:14:28.125502Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gradient_check(num_checks, delta, inputs, target, h_prev, C_prev):\n",
    "    global parameters\n",
    "    \n",
    "    # To calculate computed gradients\n",
    "    _, _, _ =  forward_backward(inputs, targets, h_prev, C_prev)\n",
    "    \n",
    "    \n",
    "    for param in parameters.all():\n",
    "        #Make a copy because this will get modified\n",
    "        d_copy = np.copy(param.d)\n",
    "\n",
    "        # Test num_checks times\n",
    "        for i in range(num_checks):\n",
    "            # Pick a random index\n",
    "            rnd_idx = int(uniform(0, param.v.size))\n",
    "            \n",
    "            grad_numerical = calc_numerical_gradient(param,\n",
    "                                                     rnd_idx,\n",
    "                                                     delta,\n",
    "                                                     inputs,\n",
    "                                                     target,\n",
    "                                                     h_prev, C_prev)\n",
    "            grad_analytical = d_copy.flat[rnd_idx]\n",
    "\n",
    "            err_sum = abs(grad_numerical + grad_analytical) + 1e-09\n",
    "            rel_error = abs(grad_analytical - grad_numerical) / err_sum\n",
    "            \n",
    "            # If relative error is greater than 1e-06\n",
    "            if rel_error > 1e-06:\n",
    "                print('%s (%e, %e) => %e'\n",
    "                      % (param.name, grad_numerical, grad_analytical, rel_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:14:35.551540Z",
     "start_time": "2020-04-02T02:14:29.999111Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_o (-1.996625e-07, -1.998168e-07) => 3.853199e-04\n",
      "W_o (3.370289e-04, 3.370305e-04) => 2.322995e-06\n",
      "W_o (-7.318590e-08, -7.264343e-08) => 3.694556e-03\n",
      "W_o (5.214673e-06, 5.214992e-06) => 3.059696e-05\n",
      "b_o (1.349839e-04, 1.349844e-04) => 1.852397e-06\n",
      "b_o (-2.459899e-06, -2.459555e-06) => 6.985951e-05\n",
      "b_o (-2.737792e-05, -2.737810e-05) => 3.248616e-06\n",
      "b_o (1.882938e-06, 1.883208e-06) => 7.159621e-05\n",
      "b_o (1.537330e-05, 1.537335e-05) => 1.648806e-06\n",
      "b_o (-1.278977e-08, -1.158426e-08) => 4.750940e-02\n",
      "b_o (-7.669456e-05, -7.669582e-05) => 8.228881e-06\n"
     ]
    }
   ],
   "source": [
    "gradient_check(10, 1e-5, inputs, targets, g_h_prev, g_C_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
